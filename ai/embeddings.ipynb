{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import backoff\n",
    "from openai.error import RateLimitError, OpenAIError\n",
    "import pandas as pd\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "\"\"\"\n",
    "This script scrapes the Microsoft Learn website for all the courses and their descriptions.\n",
    "openai example: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\n",
    "\"\"\"\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "load_dotenv()\n",
    "\n",
    "nltk.download(\"all\")\n",
    "\n",
    "class Embeddings:\n",
    "    def __init__(self, df: pd.DataFrame, token_limit: int):\n",
    "        self.df = df\n",
    "        self.token_limit = token_limit\n",
    "        self.model = \"text-embedding-ada-002\"\n",
    "\n",
    "    def count_tokens(text: str) -> int:\n",
    "        \"\"\"count the number of tokens in a string\"\"\"\n",
    "        return len(tokenizer.encode(text))\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, (RateLimitError, OpenAIError))\n",
    "    def get_embedding(self, text: str, model: str) -> list[float]:\n",
    "        result = openai.Embedding.create(model=model, input=text)\n",
    "        return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    def get_doc_embedding(self, text: str) -> list[float]:\n",
    "        return self.get_embedding(text=text, model=self.model)\n",
    "\n",
    "    def compute_query_embeddings(self, text: str) -> list[float]:\n",
    "        return self.get_embedding(text=text, model=self.model)\n",
    "\n",
    "    def compute_doc_embeddings(self) -> dict[tuple[str, str], list[float]]:\n",
    "        \"\"\"\n",
    "        Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "\n",
    "        Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            idx: self.get_doc_embedding(\n",
    "                str(r.content).replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "            )\n",
    "            for idx, r in self.df.iterrows()\n",
    "        }\n",
    "\n",
    "    def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "        \"\"\"\n",
    "        Read the document embeddings and their keys from a CSV.\n",
    "\n",
    "        fname is the path to a CSV with exactly these named columns:\n",
    "            \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_csv(fname, header=0)\n",
    "        max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "        return {\n",
    "            (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)]\n",
    "            for _, r in df.iterrows()\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-1gHcauG1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
